---
title: "Taller evaluado II"
date: "2025-10-17"
format:
  html:
    toc: true
    toc-depth: 5
lang: es
---

**Nombre y apellido de cada miembro del grupo**

* Toni Rigo
* Joan Miquel Rubi
* Monserrat Pou



```{r, message=FALSE, echo=FALSE}
library(tidyverse)
library(factoextra)
library(GGally)
library(ggplot2)
library(cluster)
ruta = "./datos_taller_evaluado_2.csv"
datos_taller_evaluado_2 = read.csv(ruta)
```



**Una consultora especializada en evaluación y gobernanza de sistemas de Inteligencia Artificial (IA) ha recopilado información de 240 organizaciones pertenecientes a los sectores de Salud y Educación que han incorporado sistemas de IA para apoyar la toma de decisiones y la automatización de procesos.**

**Para cada organización se ha medido:**

* `ID`: Identificador único de la organización/entidad observada.

* `Sector`: Sector al que pertenece la organización (Salud o Educación).

* `Implementacion`: Estado de despliegue de la solución de IA (Piloto o Producción).

* `Precision`: Precisión del sistema en escala 0–100 (a mayor valor, mejor).

* `Robustez`: Estabilidad del sistema ante cambios/ruido/datos distintos en escala 0–100 (a mayor valor, más robusto).

* `Productividad`: Ganancia o nivel de productividad asociado al uso de IA en escala 0–100 (a mayor valor, mejor).


* `Ahorro_tiempo`: Ahorro de tiempo atribuible a la IA en escala 0–100 (a mayor valor, más ahorro).

* `Riesgo_etico`: Nivel de riesgo ético percibido en escala 0–100 (a mayor valor, más riesgo).

* `Riesgo_legal`: Nivel de riesgo legal/regulatorio percibido en escala 0–100 (a mayor valor, más riesgo).

* `Aceptacion_usuarios`: Grado de aceptación por parte de usuarios finales en escala 0–100 (a mayor valor, más aceptación).

* `Coste`: Coste relativo del proyecto/solución en escala 0–100 (a mayor valor, mayor coste).


**El objetivo del estudio es comprender patrones de adopción, similitudes entre organizaciones y posibles diferencias sistemáticas entre grupos.**

**Los datos están disponibles en el archivo: "datos_taller_evaluado_2.csv"** 



#### 1. Realizad un análisis exploratorio multivariante del conjunto de datos. Para ello presentad e interpretad cada uno de los gráficos solicitados a continuación, relacionándolos  con el contexto del problema y destacando los patrones, asociaciones o diferencias relevantes que aporten información útil para comprender el uso de la IA en los distintos sectores (1 punto)

*  **Una matriz de gráficos de dispersión que incluya las correlaciones entre las variables: `Precisión`, `Robustez`,  `Productividad`, `Ahorro_tiempo` y `Aceptacion_usuarios`por `Sector`**

```{r}
vars = c("Precision", "Robustez",  "Productividad", "Ahorro_tiempo", "Aceptacion_usuarios")
datos1 = datos_taller_evaluado_2 %>% select(Sector, vars)
ggpairs(datos1,
  columns = vars,
  aes(color=Sector, alpha = 0.6),
  upper = list(continuous = wrap("cor", size = 3)),
  lower = list(continuous = wrap("points", size = 1.5)),
  diag  = list(continuous = "densityDiag")
  ) 
```
En el gráfico destaca que la mayoria de parejas de variables tienen una correlación global significativa (todas excepto `Robustez` y `Aceptación_usuarios`), la pareja que mayor correlación tiene es `Ahorro_tiempo` y `Productividad` con una correlación global de 0.855, cosa que tiene sentido porque si aumenta la productividad, entonces el tiempo usado para realizar las tareas será menor y obviamente el ahorro de tiempo será mayor. 

Otras parejas que tienen una correlación global elevada son `Robustez`y `Precision`, ligeramente mayor en el sector de salud. `Aceptacion_usuarios` y `Productividad` también tiene una correlación alta lo cual tiene sentido ya que si el usuario que va a usar la IA está de acuerdo en usarla la productividad será mayor que si el usuario no está de acuerdo en usarla, en esta pareja destaca nuevamente el sector de la Salud. Tambien es alta la correlación de `Aceptacion_usuarios` y `Ahorro_tiempo`.

La correlación global significativa más baja es la de la pareja `Aceptacion_usuarios` y `Precision`, incluso el sector de Educación tiene una correlación negativa (aunque muy cercana a 0) aunque la correlación de los sectores no es significativa. 

 
* **Una matriz de gráficos de dispersión que incluya las correlaciones entre las variables: `Riesgo_etico`, `Riesgo_legal` y `Coste` por `Sector`**

```{r}
vars2 = c("Riesgo_etico", "Riesgo_legal", "Coste")
datos2 = datos_taller_evaluado_2 %>% select(Sector, vars2)
ggpairs(datos2,
  columns = vars2,
  aes(color=Sector, alpha = 0.6),
  upper = list(continuous = wrap("cor", size = 3)),
  lower = list(continuous = wrap("points", size = 1.5)),
  diag  = list(continuous = "densityDiag")
  )
```

En este gráfico destaca que todas las correlaciones (globales y divididas por sector) son signigicativas y altas, lo que significa que en ambos sectores se ven las 3 cosas como un bloque altamente interrelacionado. La mayor es la de la pareja `Riesgo_legal` y `Riesgo_etico`, y además es casi igual en ambos sectores, esto índica que quien vea riesgo legal también suele ver riesgo ético en el uso de la IA.

En cuanto a `Coste` se ve que el sector de la educación relaciona las soluciones más costosas con un mayor riesgo (tanto legal como ético), especialmente en el sector de la Educación.




#### 2. Considerad el vector multivariante $\mathbf{Y}$, definido a continuación,  para llevar a cabo el contraste de comparación de medias entre los sectores Educación y Salud, tal y como se especifica más adelante.
$$
\mathbf{Y}=
\begin{aligned}[t]
(&\texttt{Precision},\ \texttt{Robustez},\ \texttt{Productividad},\ \texttt{Ahorro\_tiempo},\ \texttt{Aceptacion\_usuarios},\\
 &\texttt{Riesgo\_etico},\ \texttt{Riesgo\_legal},\ \texttt{Coste})
\end{aligned}
$$

$$
H_0:\ \boldsymbol{\mu}_{\text{Edu}}=\boldsymbol{\mu}_{\text{Salud}}
\qquad \text{frente a} \qquad
H_1:\ \boldsymbol{\mu}_{\text{Edu}}\neq \boldsymbol{\mu}_{\text{Salud}}.
$$

##### a. ¿Qué supuestos deben cumplirse y mencionad cómo podríais verificarlos para que sea válido aplicar uno de los test estudiados en la asignatura? (1 punto)

Para resolver este test un estadístico de contraste adecuado sería el $T^2$ de Hotelling. Para ello debe cumplirse que $Y_{Edu}$ y $Y_{Salud}$ sean independientes y sigan una distribución $N_8(\mu_{Edu},\Sigma)$ y $N_8(\mu_{Salud},\Sigma)$ respectivamente.Para ver que los dos siguen una normal multivariante podriamos hacer un QQ-plot multivariante, de esta manera si obtenemos que los datos estan más o menos sobre la diagonal, seguirán la distribución normal multivariante.En cambio, si se alejan mucho de la diagonal no lo harán. Además hay tests en R para verificar la normalidad. que las distribuciones tienen la misma matriz de covarianza, podríamos hacer un heatmap para ver visualmente las dos matrices de covarianzas muestrales y de esta forma ver si son similares

##### b. Escribid un código en R que implemente el contraste de comparación de medias multivariantes apropiado entre los sectores Educación y Salud para las variables consideradas. El código debe calcular y mostrar el vector de medias muestrales de cada sector; ejecutar el contraste. Luego, reportad el p-valor y tomar una decisión para $\alpha=0.05$ en el contexto del problema (2 puntos)

Supongamos que $Y_{Edu}$ y $Y_{Salud}$ siguen una distribución multivariante. Primero calculemos sus medias:

```{r}
library(tidyverse)
tabla_educacion <- datos_taller_evaluado_2 %>%
  filter(Sector == "Educación") %>%
  select(4:11)
tabla_Salud <- datos_taller_evaluado_2 %>%
  filter(Sector == "Salud") %>%
  select(4:11)
media_educacion = colMeans(tabla_educacion)
media_salud = colMeans(tabla_Salud)
media_educacion
media_salud
```

Ahora comprobemos si tienen la misma matriz de covarianzas. Para ello usaremos un heatmap de las matrices de covarianzas para visualizar si hay similitud entre ellas.

```{r}
library(reshape2)
library(ggplot2)

# 1. Calculamos las matrices de covarianza
s_edu <- cov(tabla_educacion)
s_salud <- cov(tabla_Salud)

# 2. Convertimos a formato largo para ggplot
edu_melt <- melt(s_edu)
salud_melt <- melt(s_salud)
edu_melt$Sector <- "Educación"
salud_melt$Sector <- "Salud"

# 3. Unimos y graficamos
df_heat <- rbind(edu_melt, salud_melt)

ggplot(df_heat, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white") +
  facet_wrap(~Sector) +
  theme_minimal() +
  labs(title = "Comparación Visual de Matrices de Covarianza",
       fill = "Valor Cov") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Como podemos ver las matrices de covarianzas muestrales son bastante similares, por tanto podemos suponer que siguen una distribución normal multivariante con la misma matriz de covarianza. Por tanto, como la matriz de covarianza es desconocida usaremos el estadístico $T^2$ de Hotelling y además $$\frac{n_1+n_2-1-p}{(n_1+n_2-2)*p}* T^2 \sim F_{n_1 + n_2 - 1 - p}^{p}$$

```{r}
S1 <- cov(tabla_educacion)
S2 <- cov(tabla_Salud)
n1 = 116
n2 = 124
p = 8
# S_hat: Estimación insesgada de la matriz de covarianza
S_hat <- (n1 * S1 + n2 * S2) / (n1 + n2 - 2)
diff <- media_educacion - media_salud
S_hat
# Estadístico T2 y transformación a F
T2 <- ((n1 * n2) / (n1 + n2)) * t(diff) %*% solve(S_hat) %*% diff
T2
constante <- (n1 + n2 - 1 - p) / ((n1 + n2 - 2) * p)
F_obs <- as.numeric(constante * T2)

# 5. REPORTE DE RESULTADOS Y DECISIÓN
p_valor <- 1 - pf(F_obs, df1 = p, df2 = n1 + n2 - 1 - p)

p_valor
```

Por tanto, si consideramos $\alpha=0.05$ rechazamos la hipótesis nula. Entonces, sí que hay diferencias significativas entre los sectores educación y salud. \#### 3. Representad de manera reducida los perfiles multivariantes del uso de IA del sector Educación y del sector Salud (por separado). Interpretad las componentes retenidas, explicando su posible significado práctico en el contexto del problema. Justificad bien el procedimiento (3 puntos)



#### 3. Representad de manera reducida los perfiles multivariantes del uso de IA del sector Educación y del sector Salud (por separado). Interpretad  las componentes retenidas, explicando su posible significado práctico en el contexto del problema. Justificad bien el procedimiento (3 puntos)

```{r educacion}
Educacion = datos_taller_evaluado_2 %>% filter(datos_taller_evaluado_2$Sector == "Educación")
educacion_num = Educacion %>% select(where(is.numeric)) %>% scale()
pca_educacion = prcomp(educacion_num)
fviz_screeplot(pca_educacion, addlabels = TRUE, ylim = c(0, 100))
```

Entonces con las dos primeras variables conseguimos mantener un 81.5% de la información.

En la primera variable del PCA la variable inicial que tiene más peso es `Riesgo_legal` con un valor muy cercano está `Riesgo_etico`, la que menos con bastante diferencia de la siguiente es `Robustez`.

En la segunda variable del PCA la variable inicial que tiene más peso es `Robustez` y después están muy cerca `Precision` y `Aceptacion_usuarios`, en este caso la que menos pesa es `Riesgo_etico` con un valor muy cercano a 0, igual que `Riesgo_legal` aunque su valor es ligeramente mayor.

Vemos que las que tienen un peso mayor en la primera tienen un peso menor en la segunda y viceversa, es por ello que mantenemos un porcentaje alto de información usando solo 2 nuevas variables.


```{r salud}
Salud = datos_taller_evaluado_2 %>% filter(datos_taller_evaluado_2$Sector == "Salud")
salud_num = Salud %>% select(where(is.numeric)) %>% scale()
pca_salud = prcomp(salud_num)
fviz_screeplot(pca_salud, addlabels = TRUE, ylim = c(0, 100))
```

Si cogemos 2 variables mantenemos un 80.2% de la información inicial.

En la primera variable vemos que las variables con un peso mayor son `Riesgo_legal` y `Riesgo_etico`, y la que menos es `Robustez`

En la segunda variable del PCA las variables iniciales que tienen más peso son `Robustez`, `Precision` y `Aceptacion_usuarios`, en este caso las que menos peso tienen son `Riesgo_etico` y `Riesgo_legal`.

De nuevo vemos que las variables que están altamente representadas en la primera están menos representadas en la segunda y viceversa, por ello mantenemos una cantidad tan alta de información solo usando dos variables.


Veamos las proyecciones de los puntos en sus dos primeras nuevas variables

```{r puntos, fig.show="hold", fig.width=10, fig.height=5}
fviz_pca_biplot(
  pca_educacion,
  geom = "point",
  alpha = 0.6,
  title = "PCA – Sector Educación"
)
fviz_pca_biplot(
  pca_salud,
  geom = "point",
  alpha = 0.6,
  title = "PCA – Sector Salud"
)
```

En estos gráficos vemos donde están los puntos en función de las dos primeras variables del PCA y las flechas nos dicen el peso de cada variable inicial. 

En ambos sectores los pesos de las variables iniciales son bastantes parecidas, ya lo hemos comentado arriba mirando `pca_educacion$rotation` y `pca_salud$rotation`.

Los puntos que estén más abajo significa que tienen un valor más alto de `Robustez` mientras que si están más arriba tienen un valor de `Aceptacion_usuarios` más alto, cuanto más a la derecha tienen un valor más alto de `Riesgo_legal` o `Riesgo_etico`

#### 4. A continuación os presentamos dos bloques de código. Explicad de forma breve qué procedimiento estadístico se aplica en cada bloque. Después, interpretad los resultados en el contexto del problema: describid qué perfiles de uso de IA emergen en el sector Educación y en qué se diferencian entre sí. Por último, compara ambos bloques y justificad cuál de los dos resultados consideráis más adecuado para describir los perfiles (3 puntos)


##### Bloque A
```{r, }
datos <- read.csv("datos_taller_evaluado_2.csv")
vars <- c("Precision","Robustez","Productividad",
          "Ahorro_tiempo","Aceptacion_usuarios",
          "Riesgo_etico","Riesgo_legal","Coste")

X_Edu <- datos %>%
  filter(Sector == "Educación") %>%
  select(all_of(vars)) %>%
  as.data.frame()

X_Edu_sc   <- scale(X_Edu)
fviz_nbclust(X_Edu_sc, FUNcluster = cluster::pam, method = "wss") +
  ggtitle("PAM - WSS (Educación)")

set.seed(123)
pam_Edu <- cluster::pam(X_Edu_sc, k = 4) 
pam_Edu

fviz_cluster(pam_Edu, data = X_Edu_sc, 
             ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none") +
  ggtitle("Clustering PAM (Educación)")

perfil <- read.csv("perfil_Edu.csv")$x
table(perfil, pam_Edu$clustering)
```
En este bloque se leen los datos y se cojen unicamente los del sector de Educacion, se consideran todas las columans menos las de Sector, ID y Implementación. Se centra y escala la matriz usando la media y la desviación tipica.
Seguidamente, se usa `fviz_nbclust` para crear un grafico de codo y deducir el numero de clusters necessario para aplicar k-medoids a través de PAM para encontrar los medoids. Se usa la suma de cuadrados de distancias para calcular la distancia intra-cluster.

Luego, usando k=4 se aplica PAM para encontrar los 4 medoids y `fviz_cluster` se usa para representar los clusters con elipses usando los medoids que se acaban de encontrar.

Finalmente, see lee el archivo `perfil_Edu.csv` y se hace una tabla de contingencia con los clusters assignados y los datos de `perfil_Edu.csv`, que contiene los perfiles reales.

En respecto a los resultados, tenemos que cada cluster tiene carateristicas bastante diferentes:
En el cluster 1 vemos un perfil de uso con una precisión, robustez, risego etico y coste bastante por debajo de la media. Destacamos que en el cluster 1 tenemos una precisión muy baja.
En el cluster 2 vemos valores moderadamente por encima de la media en todas las mediciones excepto en la robustez. Donde destacamos el cluster con mayor aceptación positiva.
En el cluster 3 vemos valores muy por encima de la media en todas las mediciones excepto la aceptacion de los usuarios. Destacamos la alta robustez y coste que se le assigna a este cluster.
En el cluster 4 vemos valores muy por debajo de la media en todas las mediciones excepto en la robustez y la precision, que estan un poco por encima y sobre la media, respectivamente. Donde destacamos un riesgo laboral y aceptación muy negativos.

Mirando la tabla de contingencia vemos que el clustering no es similar al real porque en la fila uno y cuatro tenemos los datos distribuidos entre dos clusters mayoritariamente.

##### Bloque B
```{r, warning=FALSE}
matriz_distancias <- dist(X_Edu_sc, method = "euclidean")
h_cluster_average <- hclust(d = matriz_distancias, method = "average")
cor(matriz_distancias, cophenetic(h_cluster_average))
fviz_dend(h_cluster_average, k = 4, cex = 0.4, rect = TRUE,
          main = "Dendrograma (average) - Educación")
average_clusters <- cutree(h_cluster_average, k = 4)
table(perfil, average_clusters)
```

En ese bloque se cojen los datos escalados y se crea la matriz de distancias euclideas. Luego se realiza clustering jerárquico sobre la matriz de distancias utilizando la mediana como metodo algomerativo. Seguidamente se calcula la covarianza entre la matriz de distancias y las distancias cofenéticas del clustering jerárquico. Se representan los resultados del clustering en un dendograma utilizando `fviz_dend` y con `cutree`se crean 4 clusters.
Luego se crea una tabla de contingencia entre estos ultimos clusters y los perfiles reales.

Vemos que hay un cluster muy pequeño, con unicamente dos observaciones y otro que ocupa la mayoria del las observaciones. Tambien destacamos que este cluster estaria aislado ya que se une a la jerarquia en el ultimo paso.

En la tabla de contingencia tenemos que los clusters tampoco se asemejan los reales de `prefil_Edu.csv`, tendiendo el cluster numero 2 repartido en tres trozos grandes en los clusters de `perfil_Edu.csv` numero 1, 3 y 4.

Comparando los dos clusterings vemos que ninguno se asemeja al descrito por `perfil_Edu.csv`, aun así en el Bloque B destacamos la deteción de los valores aislados numero 69 y 58 que fueron assignados a un gran cluster en el Bloque A, aun asi de estar muy fuera del elipse del cluster assignado. Aun así en el Bloque B tenemos un cluster ocupando la mayoria de los valores, que dificulta la caracterización de los datos ya que tendriamos un bloque "general" con mucha varianza.
Comparando los tamaños del los clusters vemos que efectivamente los clusters del Bloque B son mucho menos homogeneos (especialmente por el cluster de tamaño dos), mientras que los clusters de el Bloque A son de tamaño muy similar los cuatro. Luego el Bloque A seria un clustering mejor por este razonamiento.


**Instrucciones para entregar:**
Un miembro del grupo deberá subir a la tarea de Aula Digital, un único archivo PDF que incluya:  
1) los nombres de todos los integrantes, y  
2) un enlace al repositorio de GitHub (de cualquiera de los integrantes).  

El repositorio deberá contener, como mínimo:  
- el archivo fuente `.qmd`,  
- la salida `.html`, y  
- un `README.md` que describa con claridad el propósito del proyecto y su estructura.


