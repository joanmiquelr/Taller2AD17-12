---
title: "Taller evaluado II"
date: "2025-10-17"
format:
  html:
    toc: true
    toc-depth: 5
lang: es
---

**Nombre y apellido de cada miembro del grupo**

* Estudiante 1
* Estudiante 2
* Estudiante 3



```{r, message=FALSE, echo=FALSE}
library("tidyverse")
library("ggplot2")
library("cluster")
```



**Una consultora especializada en evaluación y gobernanza de sistemas de Inteligencia Artificial (IA) ha recopilado información de 240 organizaciones pertenecientes a los sectores de Salud y Educación que han incorporado sistemas de IA para apoyar la toma de decisiones y la automatización de procesos.**

**Para cada organización se ha medido:**

* `ID`: Identificador único de la organización/entidad observada.

* `Sector`: Sector al que pertenece la organización (Salud o Educación).

* `Implementacion`: Estado de despliegue de la solución de IA (Piloto o Producción).

* `Precision`: Precisión del sistema en escala 0–100 (a mayor valor, mejor).

* `Robustez`: Estabilidad del sistema ante cambios/ruido/datos distintos en escala 0–100 (a mayor valor, más robusto).

* `Productividad`: Ganancia o nivel de productividad asociado al uso de IA en escala 0–100 (a mayor valor, mejor).


* `Ahorro_tiempo`: Ahorro de tiempo atribuible a la IA en escala 0–100 (a mayor valor, más ahorro).

* `Riesgo_etico`: Nivel de riesgo ético percibido en escala 0–100 (a mayor valor, más riesgo).

* `Riesgo_legal`: Nivel de riesgo legal/regulatorio percibido en escala 0–100 (a mayor valor, más riesgo).

* `Aceptacion_usuarios`: Grado de aceptación por parte de usuarios finales en escala 0–100 (a mayor valor, más aceptación).

* `Coste`: Coste relativo del proyecto/solución en escala 0–100 (a mayor valor, mayor coste).


**El objetivo del estudio es comprender patrones de adopción, similitudes entre organizaciones y posibles diferencias sistemáticas entre grupos.**

**Los datos están disponibles en el archivo: "datos_taller_evaluado_2.csv"** 



#### 1. Realizad un análisis exploratorio multivariante del conjunto de datos. Para ello presentad e interpretad cada uno de los gráficos solicitados a continuación, relacionándolos  con el contexto del problema y destacando los patrones, asociaciones o diferencias relevantes que aporten información útil para comprender el uso de la IA en los distintos sectores (1 punto)

*  **Una matriz de gráficos de dispersión que incluya las correlaciones entre las variables: `Precisión`, `Robustez`,  `Productividad`, `Ahorro_tiempo` y `Aceptacion_usuarios`por `Sector`**
 
* **Una matriz de gráficos de dispersión que incluya las correlaciones entre las variables: `Riesgo_etico`, `Riesgo_legal` y `Coste` por `Sector`**



#### 2. Considerad el vector multivariante $\mathbf{Y}$, definido a continuación,  para llevar a cabo el contraste de comparación de medias entre los sectores Educación y Salud, tal y como se especifica más adelante.
$$
\mathbf{Y}=
\begin{aligned}[t]
(&\texttt{Precision},\ \texttt{Robustez},\ \texttt{Productividad},\ \texttt{Ahorro\_tiempo},\ \texttt{Aceptacion\_usuarios},\\
 &\texttt{Riesgo\_etico},\ \texttt{Riesgo\_legal},\ \texttt{Coste})
\end{aligned}
$$

$$
H_0:\ \boldsymbol{\mu}_{\text{Edu}}=\boldsymbol{\mu}_{\text{Salud}}
\qquad \text{frente a} \qquad
H_1:\ \boldsymbol{\mu}_{\text{Edu}}\neq \boldsymbol{\mu}_{\text{Salud}}.
$$

##### a. ¿Qué supuestos deben cumplirse y mencionad cómo podríais verificarlos para que sea válido aplicar uno de los test estudiados en la asignatura? (1 punto)


##### b. Escribid un código en R que implemente el contraste de comparación de medias multivariantes apropiado entre los sectores Educación y Salud para las variables consideradas. El código debe calcular y mostrar el vector de medias muestrales de cada sector; ejecutar el contraste. Luego,  reportad el p-valor y tomar una decisión para $\alpha=0.05$ en el contexto del problema (2 puntos)



#### 3. Representad de manera reducida los perfiles multivariantes del uso de IA del sector Educación y del sector Salud (por separado). Interpretad  las componentes retenidas, explicando su posible significado práctico en el contexto del problema. Justificad bien el procedimiento (3 puntos)


#### 4. A continuación os presentamos dos bloques de código. Explicad de forma breve qué procedimiento estadístico se aplica en cada bloque. Después, interpretad los resultados en el contexto del problema: describid qué perfiles de uso de IA emergen en el sector Educación y en qué se diferencian entre sí. Por último, compara ambos bloques y justificad cuál de los dos resultados consideráis más adecuado para describir los perfiles (3 puntos)


##### Bloque A
```{r, }
datos <- read.csv("datos_taller_evaluado_2.csv")
vars <- c("Precision","Robustez","Productividad",
          "Ahorro_tiempo","Aceptacion_usuarios",
          "Riesgo_etico","Riesgo_legal","Coste")

X_Edu <- datos %>%
  filter(Sector == "Educación") %>%
  select(all_of(vars)) %>%
  as.data.frame()

X_Edu_sc   <- scale(X_Edu)
fviz_nbclust(X_Edu_sc, FUNcluster = cluster::pam, method = "wss") +
  ggtitle("PAM - WSS (Educación)")

set.seed(123)
pam_Edu <- cluster::pam(X_Edu_sc, k = 4) 
pam_Edu

fviz_cluster(pam_Edu, data = X_Edu_sc, 
             ellipse.type = "t", repel = TRUE) +
  theme_bw() + theme(legend.position = "none") +
  ggtitle("Clustering PAM (Educación)")

perfil <- read.csv("perfil_Edu.csv")$x
table(perfil, pam_Edu$clustering)
```
En este bloque se leen los datos y se cojen unicamente los del sector de Educacion, se consideran todas las columans menos las de Sector, ID y Implementación. Se centra y escala la matriz usando la media y la desviación tipica.
Seguidamente, se usa `fviz_nbclust` para crear un grafico de codo y deducir el numero de clusters necessario para aplicar k-medoids a través de PAM para encontrar los medoids. Se usa la suma de cuadrados de distancias para calcular la distancia intra-cluster.

Luego, usando k=4 se aplica PAM para encontrar los 4 medoids y `fviz_cluster` se usa para representar los clusters con elipses usando los medoids que se acaban de encontrar.

Finalmente, see lee el archivo `perfil_Edu.csv` y se hace una tabla de contingencia con los clusters assignados y los datos de `perfil_Edu.csv`, que contiene los perfiles reales.

En respecto a los resultados, tenemos que cada cluster tiene carateristicas bastante diferentes:
En el cluster 1 vemos un perfil de uso con una precisión, robustez, risego etico y coste bastante por debajo de la media. Destacamos que en el cluster 1 tenemos una precisión muy baja.
En el cluster 2 vemos valores moderadamente por encima de la media en todas las mediciones excepto en la robustez. Donde destacamos el cluster con mayor aceptación positiva.
En el cluster 3 vemos valores muy por encima de la media en todas las mediciones excepto la aceptacion de los usuarios. Destacamos la alta robustez y coste que se le assigna a este cluster.
En el cluster 4 vemos valores muy por debajo de la media en todas las mediciones excepto en la robustez y la precision, que estan un poco por encima y sobre la media, respectivamente. Donde destacamos un riesgo laboral y aceptación muy negativos.

Mirando la tabla de contingencia vemos que el clustering no es similar al real porque en la fila uno y cuatro tenemos los datos distribuidos entre dos clusters mayoritariamente.

##### Bloque B
```{r, warning=FALSE}
matriz_distancias <- dist(X_Edu_sc, method = "euclidean")
h_cluster_average <- hclust(d = matriz_distancias, method = "average")
cor(matriz_distancias, cophenetic(h_cluster_average))
fviz_dend(h_cluster_average, k = 4, cex = 0.4, rect = TRUE,
          main = "Dendrograma (average) - Educación")
average_clusters <- cutree(h_cluster_average, k = 4)
table(perfil, average_clusters)
```

En ese bloque se cojen los datos escalados y se crea la matriz de distancias euclideas. Luego se realiza clustering jerárquico sobre la matriz de distancias utilizando la mediana como metodo algomerativo. Seguidamente se calcula la covarianza entre la matriz de distancias y las distancias cofenéticas del clustering jerárquico. Se representan los resultados del clustering en un dendograma utilizando `fviz_dend` y con `cutree`se crean 4 clusters.
Luego se crea una tabla de contingencia entre estos ultimos clusters y los perfiles reales.

Vemos que hay un cluster muy pequeño, con unicamente dos observaciones y otro que ocupa la mayoria del las observaciones. Tambien destacamos que este cluster estaria aislado ya que se une a la jerarquia en el ultimo paso.

En la tabla de contingencia tenemos que los clusters tampoco se asemejan los reales de `prefil_Edu.csv`, tendiendo el cluster numero 2 repartido en tres trozos grandes en los clusters de `perfil_Edu.csv` numero 1, 3 y 4.

Comparando los dos clusterings vemos que ninguno se asemeja al descrito por `perfil_Edu.csv`, aun así en el Bloque B destacamos la deteción de los valores aislados numero 69 y 58 que fueron assignados a un gran cluster en el Bloque A, aun asi de estar muy fuera del elipse del cluster assignado. Aun así en el Bloque B tenemos un cluster ocupando la mayoria de los valores, que dificulta la caracterización de los datos ya que tendriamos un bloque "general" con mucha varianza.
Comparando los tamaños del los clusters vemos que efectivamente los clusters del Bloque B son mucho menos homogeneos (especialmente por el cluster de tamaño dos), mientras que los clusters de el Bloque A son de tamaño muy similar los cuatro. Luego el Bloque A seria un clustering mejor por este razonamiento.


**Instrucciones para entregar:**
Un miembro del grupo deberá subir a la tarea de Aula Digital, un único archivo PDF que incluya:  
1) los nombres de todos los integrantes, y  
2) un enlace al repositorio de GitHub (de cualquiera de los integrantes).  

El repositorio deberá contener, como mínimo:  
- el archivo fuente `.qmd`,  
- la salida `.html`, y  
- un `README.md` que describa con claridad el propósito del proyecto y su estructura.


